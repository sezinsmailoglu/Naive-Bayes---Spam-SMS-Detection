{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7df702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "class multinomialNaiveBayes:\n",
    "    \n",
    "    def __init__(self, training_features, training_labels):\n",
    "        start = timeit.default_timer()\n",
    "        self.numOfMessages = len(training_labels)\n",
    "        self.numOfFeatures = len(training_features[0])\n",
    "        self.FeaturePerLabel_0 = [0]*self.numOfFeatures # given label 0, the feature x has been observed FeaturePerLabel_0[x] times\n",
    "        self.FeaturePerLabel_1 = [0]*self.numOfFeatures # given label 1, the feature x has been observed FeaturePerLabel_1[x] times\n",
    "        \n",
    "        for featureNum in range(0,self.numOfFeatures):\n",
    "            for row in range(0,len(training_labels)):\n",
    "                if (training_labels[row] == 0):\n",
    "                    self.FeaturePerLabel_0[featureNum] += training_features[row,featureNum]\n",
    "                else:\n",
    "                    self.FeaturePerLabel_1[featureNum] += training_features[row,featureNum]\n",
    "        \n",
    "        self.numOfSpams = 0\n",
    "        for message in range(0, len(training_labels)):\n",
    "            self.numOfSpams += training_labels[message] #the label of spam is 1 so adding all of the array gives the spam num\n",
    "        self.numOfNonSpam = self.numOfMessages - self.numOfSpams\n",
    "        self.totalNumOfWords = 0;\n",
    "        for i in range(0,self.numOfFeatures):\n",
    "            self.totalNumOfWords += self.FeaturePerLabel_0[i] + self.FeaturePerLabel_1[i]\n",
    "        self.totalNumOfWordsinNonSpam = 0\n",
    "        self.totalNumOfWordsinSpam = 0\n",
    "        for i in range(0,self.numOfFeatures):\n",
    "            self.totalNumOfWordsinSpam += self.FeaturePerLabel_1[i]\n",
    "            self.totalNumOfWordsinNonSpam += self.FeaturePerLabel_0[i]\n",
    " \n",
    "        stop = timeit.default_timer()\n",
    "        print('training time: ', stop - start)\n",
    "    \n",
    "    #keeping numOfMessages, numOfFeatures, FeaturePerLabel_0, FeaturePerLabel_1, numOfSpams, numOfNonSpam, totalNumOfWords\n",
    "        \n",
    "    def probabilityOfLabel(self, label):\n",
    "        assert ((label == 0) or (label == 1)), \"label num can only be 0 or 1\"\n",
    "        if (label == 0):\n",
    "            return self.numOfNonSpam/self.numOfMessages\n",
    "        else:\n",
    "            return self.numOfSpams/self.numOfMessages\n",
    "        \n",
    "    def probabilityOfFeature(self, featureNum):\n",
    "        return (self.FeaturePerLabel_0[featureNum] + self.FeaturePerLabel_1[featureNum])/self.totalNumOfWords\n",
    "        \n",
    "    def probabilityOfFeatureGivenLabel(self, featureNum, label):\n",
    "        assert self.probabilityOfLabel(label) != 0, 'probabilityOfLabel cannot be zero'\n",
    "        if label == 0:           \n",
    "            return (self.FeaturePerLabel_0[featureNum]/self.totalNumOfWordsinNonSpam)\n",
    "        else:\n",
    "            return (self.FeaturePerLabel_1[featureNum]/self.totalNumOfWordsinSpam)\n",
    "                \n",
    "    def probabilityOfLabelGivenFeature(self, featureNum, label):\n",
    "        if self.probabilityOfFeature(featureNum) != 0:\n",
    "            if label == 0:\n",
    "                return self.FeaturePerLabel_0[featureNum]/(self.FeaturePerLabel_0[featureNum]+self.FeaturePerLabel_1[featureNum])\n",
    "            else:\n",
    "\n",
    "                return self.FeaturePerLabel_1[featureNum]/(self.FeaturePerLabel_0[featureNum]+self.FeaturePerLabel_1[featureNum])\n",
    "        else:\n",
    "            return 0            \n",
    "        \n",
    "    def jointProbability(featureNum, labelNum):\n",
    "        return probabilityOfFeatureGivenLabel(featureNum,label)*self.probabilityOfLabel(label)   \n",
    "        \n",
    "        \n",
    "    def predict(self,sample):\n",
    "           # assert len(sample) == self.numOfFeatures, \"sample has problems\"\n",
    "        prediction_label_0 = np.log(self.probabilityOfLabel(0))\n",
    "        prediction_label_1 = np.log(self.probabilityOfLabel(1))\n",
    "        for i in range(0, self.numOfFeatures):\n",
    "            probabilityOfNonSpam = self.probabilityOfFeatureGivenLabel(i,0)\n",
    "            probabilityOfSpam = self.probabilityOfFeatureGivenLabel(i,1)\n",
    "            if sample[i] != 0:\n",
    "                prediction_label_0 += sample[i]*np.log(probabilityOfNonSpam)\n",
    "                prediction_label_1 += sample[i]*np.log(probabilityOfSpam)\n",
    "    \n",
    "        if prediction_label_0 > prediction_label_1:\n",
    "            return 0\n",
    "        elif prediction_label_0 == prediction_label_1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    #keeping numOfMessages, numOfFeatures, FeaturePerLabel_0, FeaturePerLabel_1, numOfSpams, numOfNonSpam, totalNumOfWords\n",
    "    \n",
    "    def learnFromSample(self, sample,sampleLabel):\n",
    "        assert len(sample) == self.numOfFeatures, \"sample not valid\"\n",
    "        if sampleLabel == 0:\n",
    "            self.numOfNonSpam += 1\n",
    "            self.numOfMessages += 1\n",
    "            for i in range(0,len(sample)):\n",
    "                self.FeaturePerLabel_0[i] += sample[i]\n",
    "                self.totalNumOfWordsinNonSpam += sample[i]\n",
    "                self.totalNumOfWords += sample[i]\n",
    "        else:\n",
    "            self.numOfSpams += 1\n",
    "            self.numOfMessages += 1\n",
    "            for i in range(0,len(sample)):\n",
    "                self.FeaturePerLabel_1[i] += sample[i]\n",
    "                self.totalNumOfWordsinNonSpam += sample[i]\n",
    "                self.totalNumOfWords += sample[i]     \n",
    "        #todo mutual information   \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1e1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(gt_y, pred_y):\n",
    "    correct = 0\n",
    "    for g_y, p_y in zip(gt_y, pred_y):\n",
    "        if g_y == p_y: \n",
    "            correct += 1\n",
    "            \n",
    "    return (correct/float(len(gt_y))*100)\n",
    "\n",
    "def confusion_matrix(correct_labels, predictions):\n",
    "    confusion = [[0,0], [0, 0]]\n",
    "    #tp fn; fp tn\n",
    "    for l, p in zip(correct_labels, predictions):\n",
    "        if l == p:\n",
    "            if l == 0: #true negative\n",
    "                confusion[1][1] += 1\n",
    "            else:      #true positive\n",
    "                confusion[0][0] += 1\n",
    "        else: \n",
    "            if l == 0: #false positive\n",
    "                confusion[1][0] += 1\n",
    "            else: # false negative\n",
    "                confusion[0][1] += 1\n",
    "                \n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35e8721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  27.919546399993123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/1874244885.py:82: RuntimeWarning: divide by zero encountered in log\n",
      "  prediction_label_0 += sample[i]*np.log(probabilityOfNonSpam)\n",
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/1874244885.py:83: RuntimeWarning: divide by zero encountered in log\n",
      "  prediction_label_1 += sample[i]*np.log(probabilityOfSpam)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation time:  29.817757899989374\n",
      "94.3762781186094\n",
      "[[99, 41], [14, 824]]\n"
     ]
    }
   ],
   "source": [
    "#get the data\n",
    "\n",
    "#root = 'C:/Users/sezin/Desktop/SON SENE/CS464-Machine Learning/HW1/q3/'\n",
    "#csv_path_training_data = os.path.join(root, 'sms_train_features.csv')\n",
    "#csv_path_test_data = os.path.join(root, 'sms_test_features.csv')\n",
    "#csv_path_training_label = os.path.join(root, 'sms_train_labels.csv')\n",
    "#csv_path_test_label = os.path.join(root, 'sms_test_labels.csv')\n",
    "\n",
    "csv_path_training_data =  'sms_train_features.csv'\n",
    "csv_path_test_data = 'sms_test_features.csv'\n",
    "csv_path_training_label = 'sms_train_labels.csv'\n",
    "csv_path_test_label = 'sms_test_labels.csv'\n",
    "\n",
    "def get_dataset(filename):\n",
    "     with open(filename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        next(lines)\n",
    "        dataset = list(lines)\n",
    "        data = np.array([[float(row[col_i]) for col_i in range(1,len(row))] for row in dataset])\n",
    "        #print(data)\n",
    "        return data\n",
    "    \n",
    "train_features = get_dataset(csv_path_training_data)\n",
    "test_features = get_dataset(csv_path_test_data)\n",
    "train_labels = get_dataset(csv_path_training_label)\n",
    "test_labels = get_dataset(csv_path_test_label)\n",
    "\n",
    "naiveBayes1 = multinomialNaiveBayes(train_features,train_labels)\n",
    "predictions = []\n",
    "start = timeit.default_timer()\n",
    "for j in range(0,len(test_labels)):\n",
    "    prediction = naiveBayes1.predict(test_features[j])\n",
    "    predictions.append(prediction)\n",
    "stop = timeit.default_timer()\n",
    "print('validation time: ', stop - start)\n",
    "\n",
    "\n",
    "print(calc_accuracy(test_labels , predictions))\n",
    "print(confusion_matrix(test_labels , predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f958115",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/1874244885.py:82: RuntimeWarning: divide by zero encountered in log\n",
      "  prediction_label_0 += sample[i]*np.log(probabilityOfNonSpam)\n",
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/1874244885.py:83: RuntimeWarning: divide by zero encountered in log\n",
      "  prediction_label_1 += sample[i]*np.log(probabilityOfSpam)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(0, len(test_labels)):\n",
    "    naiveBayes1.learnFromSample(test_features[i],test_labels[i])\n",
    "\n",
    "new_predictions = []\n",
    "for j in range(0,len(test_labels)):\n",
    "    prediction = naiveBayes1.predict(test_features[j])\n",
    "    new_predictions.append(prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40eebaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.95501022494888\n",
      "[[137, 3], [17, 821]]\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy(test_labels , new_predictions))\n",
    "print(confusion_matrix(test_labels , new_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3100ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bernoulliNaiveBayes:\n",
    "    \n",
    "    def __init__(self, training_features, training_labels):\n",
    "        start = timeit.default_timer()\n",
    "        self.numOfMessages = len(training_labels)\n",
    "        self.numOfFeatures = len(training_features[0])\n",
    "        \n",
    "        self.FeaturePerLabel_0 = [0]*self.numOfFeatures # given label 0, the feature x has been observed FeaturePerLabel_0[x] times\n",
    "        self.FeaturePerLabel_1 = [0]*self.numOfFeatures # given label 1, the feature x has been observed FeaturePerLabel_1[x] times\n",
    "        \n",
    "        for featureNum in range(0,self.numOfFeatures):\n",
    "            for row in range(0,len(training_labels)):\n",
    "                if(training_features[row,featureNum] > 0):\n",
    "                    if (training_labels[row] == 0):\n",
    "                        self.FeaturePerLabel_0[featureNum] += 1\n",
    "                    else:\n",
    "                        self.FeaturePerLabel_1[featureNum] += 1\n",
    "        \n",
    "        self.numOfSpams = 0\n",
    "        for message in range(0, len(training_labels)):\n",
    "            self.numOfSpams += training_labels[message] #the label of spam is 1 so adding all of the array gives the spam num\n",
    "        self.numOfNonSpam = self.numOfMessages - self.numOfSpams\n",
    "        self.totalNumOfWords = 0;\n",
    "        for i in range(0,self.numOfFeatures):\n",
    "            self.totalNumOfWords += self.FeaturePerLabel_0[i] + self.FeaturePerLabel_1[i]\n",
    "        self.totalNumOfWordsinNonSpam = 0\n",
    "        self.totalNumOfWordsinSpam = 0\n",
    "        for i in range(0,self.numOfFeatures):\n",
    "            self.totalNumOfWordsinSpam += self.FeaturePerLabel_1[i]\n",
    "            self.totalNumOfWordsinNonSpam += self.FeaturePerLabel_0[i]\n",
    "        \n",
    "        stop = timeit.default_timer()\n",
    "\n",
    "        print('training time: ', stop - start)\n",
    "    \n",
    "    #keeping numOfMessages, numOfFeatures, FeaturePerLabel_0, FeaturePerLabel_1, numOfSpams, numOfNonSpam, totalNumOfWords\n",
    "        \n",
    "    def probabilityOfLabel(self, label):\n",
    "        assert ((label == 0) or (label == 1)), \"label num can only be 0 or 1\"\n",
    "        if (label == 0):\n",
    "            return self.numOfNonSpam/self.numOfMessages\n",
    "        else:\n",
    "            return self.numOfSpams/self.numOfMessages\n",
    "        \n",
    "    def probabilityOfFeature(self, featureNum):\n",
    "        return (self.FeaturePerLabel_0[featureNum] + self.FeaturePerLabel_1[featureNum])/self.totalNumOfWords\n",
    "        \n",
    "    def probabilityOfFeatureGivenLabel(self, featureNum, label):\n",
    "        assert self.probabilityOfLabel(label) != 0, 'probabilityOfLabel cannot be zero'\n",
    "        if label == 0:           \n",
    "            return (self.FeaturePerLabel_0[featureNum]/self.totalNumOfWordsinNonSpam)\n",
    "        else:\n",
    "            return (self.FeaturePerLabel_1[featureNum]/self.totalNumOfWordsinSpam)\n",
    "                \n",
    "    def probabilityOfLabelGivenFeature(self, featureNum, label):\n",
    "        if self.probabilityOfFeature(featureNum) != 0:\n",
    "            if label == 0:\n",
    "                return self.FeaturePerLabel_0[featureNum]/(self.FeaturePerLabel_0[featureNum]+self.FeaturePerLabel_1[featureNum])\n",
    "            else:\n",
    "\n",
    "                return self.FeaturePerLabel_1[featureNum]/(self.FeaturePerLabel_0[featureNum]+self.FeaturePerLabel_1[featureNum])\n",
    "        else:\n",
    "            return 0            \n",
    "        \n",
    "    def jointProbability(self,featureNum, labelNum):\n",
    "        return self.probabilityOfFeatureGivenLabel(featureNum,labelNum)*self.probabilityOfLabel(labelNum)\n",
    "\n",
    "        \n",
    "    def predict(self,sample):\n",
    "           # assert len(sample) == self.numOfFeatures, \"sample has problems\"\n",
    "        prediction_label_0 = np.log(self.probabilityOfLabel(0))\n",
    "        prediction_label_1 = np.log(self.probabilityOfLabel(1))\n",
    "        for i in range(0, self.numOfFeatures):\n",
    "            probabilityOfNonSpam = self.probabilityOfFeatureGivenLabel(i,0)\n",
    "            probabilityOfSpam = self.probabilityOfFeatureGivenLabel(i,1)\n",
    "            if sample[i] != 0:\n",
    "                prediction_label_0 += np.log(probabilityOfNonSpam)\n",
    "                prediction_label_1 += np.log(probabilityOfSpam)\n",
    "    \n",
    "        if prediction_label_0 > prediction_label_1:\n",
    "            return 0\n",
    "        elif prediction_label_0 == prediction_label_1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    #keeping numOfMessages, numOfFeatures, FeaturePerLabel_0, FeaturePerLabel_1, numOfSpams, numOfNonSpam, totalNumOfWords\n",
    "    \n",
    "    def learnFromSample(self, sample,sampleLabel):\n",
    "        assert len(sample) == self.numOfFeatures, \"sample not valid\"\n",
    "        if sampleLabel == 0:\n",
    "            self.numOfNonSpam += 1\n",
    "            self.numOfMessages += 1\n",
    "            for i in range(0,len(sample)):\n",
    "                self.FeaturePerLabel_0[i] += 1\n",
    "                self.totalNumOfWordsinNonSpam += 1 \n",
    "                self.totalNumOfWords += 1\n",
    "        else:\n",
    "            self.numOfSpams += 1\n",
    "            self.numOfMessages += 1\n",
    "            for i in range(0,len(sample)):\n",
    "                self.FeaturePerLabel_1[i] += 1\n",
    "                self.totalNumOfWordsinNonSpam +=1\n",
    "                self.totalNumOfWords += 1        \n",
    "        #todo mutual information    \n",
    "  \n",
    "    def mutual_information(self,featureNum):\n",
    "        if self.numOfMessages > 0 and ((self.FeaturePerLabel_0[featureNum] + self.FeaturePerLabel_1[featureNum]) * self.totalNumOfWordsinNonSpam)  > 0:\n",
    "            entropy_of_featureNum00 = (self.FeaturePerLabel_0[featureNum]/self.numOfMessages)*np.log2( (self.numOfMessages*self.FeaturePerLabel_0[featureNum])/ (((self.FeaturePerLabel_0[featureNum] + self.FeaturePerLabel_1[featureNum]) * self.totalNumOfWordsinNonSpam)  ))\n",
    "            entropy_of_featureNum01 = (self.FeaturePerLabel_1[featureNum]/self.numOfMessages)*np.log2((self.numOfMessages*self.FeaturePerLabel_1[featureNum])/ (((self.FeaturePerLabel_0[featureNum]+self.FeaturePerLabel_1[featureNum]) * self.totalNumOfWordsinSpam)  ))                                                           \n",
    "            return entropy_of_featureNum00 + entropy_of_featureNum01\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def selectFeaturesUsingMutualInformation(self,featureNumToBeSelected): #returns new training data column numbers\n",
    "    #open and train a new model after obtaining new training data\n",
    "        assert featureNumToBeSelected < self.numOfFeatures\n",
    "        mutualInfo = [0]*self.numOfFeatures\n",
    "        #sorted(range(len(s)), key=lambda k: s[k])\n",
    "        for i in range(0, self.numOfFeatures):\n",
    "            mutualInfo[i] = self.mutual_information(i)\n",
    "        sorted_mutualInfo_index = np.argsort(mutualInfo)\n",
    "        \n",
    "        selected_features = [0]*featureNumToBeSelected\n",
    "        for i in range(0,featureNumToBeSelected):\n",
    "            selected_features[i] = sorted_mutualInfo_index[i]\n",
    "        selected_features.sort()\n",
    "        return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88fdbdcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  5.352794100006577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/252096302.py:77: RuntimeWarning: divide by zero encountered in log\n",
      "  prediction_label_0 += np.log(probabilityOfNonSpam)\n",
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/252096302.py:78: RuntimeWarning: divide by zero encountered in log\n",
      "  prediction_label_1 += np.log(probabilityOfSpam)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation time:  23.974467499996535\n",
      "94.3762781186094\n",
      "[[99, 41], [14, 824]]\n"
     ]
    }
   ],
   "source": [
    "naiveBayes2 = bernoulliNaiveBayes(train_features,train_labels)\n",
    "predictions = []\n",
    "start = timeit.default_timer()\n",
    "for j in range(0,len(test_labels)):\n",
    "    prediction = naiveBayes2.predict(test_features[j])\n",
    "    predictions.append(prediction)\n",
    "stop = timeit.default_timer()\n",
    "print('validation time: ', stop - start)\n",
    "print(calc_accuracy(test_labels , predictions))\n",
    "print(confusion_matrix(test_labels , predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5ca569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(naiveBayes2.probabilityOfLabelGivenFeature(1,0))\n",
    "print(naiveBayes2.probabilityOfLabelGivenFeature(1,0)+naiveBayes2.probabilityOfLabelGivenFeature(1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1951bbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/252096302.py:110: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropy_of_featureNum01 = (self.FeaturePerLabel_1[featureNum]/self.numOfMessages)*np.log2((self.numOfMessages*self.FeaturePerLabel_1[featureNum])/ (((self.FeaturePerLabel_0[featureNum]+self.FeaturePerLabel_1[featureNum]) * self.totalNumOfWordsinSpam)  ))\n",
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/252096302.py:110: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  entropy_of_featureNum01 = (self.FeaturePerLabel_1[featureNum]/self.numOfMessages)*np.log2((self.numOfMessages*self.FeaturePerLabel_1[featureNum])/ (((self.FeaturePerLabel_0[featureNum]+self.FeaturePerLabel_1[featureNum]) * self.totalNumOfWordsinSpam)  ))\n",
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/252096302.py:109: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropy_of_featureNum00 = (self.FeaturePerLabel_0[featureNum]/self.numOfMessages)*np.log2( (self.numOfMessages*self.FeaturePerLabel_0[featureNum])/ (((self.FeaturePerLabel_0[featureNum] + self.FeaturePerLabel_1[featureNum]) * self.totalNumOfWordsinNonSpam)  ))\n",
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/252096302.py:109: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  entropy_of_featureNum00 = (self.FeaturePerLabel_0[featureNum]/self.numOfMessages)*np.log2( (self.numOfMessages*self.FeaturePerLabel_0[featureNum])/ (((self.FeaturePerLabel_0[featureNum] + self.FeaturePerLabel_1[featureNum]) * self.totalNumOfWordsinNonSpam)  ))\n"
     ]
    }
   ],
   "source": [
    "select100 = naiveBayes2.selectFeaturesUsingMutualInformation(100)\n",
    "select200 = naiveBayes2.selectFeaturesUsingMutualInformation(200)\n",
    "select300 = naiveBayes2.selectFeaturesUsingMutualInformation(300)\n",
    "select400 = naiveBayes2.selectFeaturesUsingMutualInformation(400)\n",
    "select500 = naiveBayes2.selectFeaturesUsingMutualInformation(500)\n",
    "select600 = naiveBayes2.selectFeaturesUsingMutualInformation(600)\n",
    "\n",
    "def eliminate_feature(feature, x):\n",
    "    if x == 0:\n",
    "        return np.array([[float(row[col_i]) for col_i in range(1,len(row))] for row in feature])\n",
    "    elif x == feature.shape[1]-1:\n",
    "        return np.array([[float(row[col_i]) for col_i in range(0,len(row)-1)] for row in feature])\n",
    "    elif x < feature.shape[1]-1:\n",
    "        firstPart = np.array([[float(row[col_i]) for col_i in range(0,x)] for row in feature])\n",
    "        secondPart = np.array([[float(row[col_i]) for col_i in range(x+1,len(row))] for row in feature])\n",
    "        return np.concatenate((firstPart, secondPart), axis=1)\n",
    "    else:\n",
    "        return feature\n",
    "    \n",
    "def eliminate_except(feature, featuresToKeep):\n",
    "    return np.array([[float(row[col_i]) for col_i in featuresToKeep] for row in feature])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83e9d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1\n",
      "t2\n",
      "t3\n",
      "t4\n",
      "t5\n",
      "t6\n",
      "training time:  0.12312740000197664\n",
      "validation time:  0.7170031000277959\n",
      "100 features:\n",
      "91.8200408997955\n",
      "[[85, 55], [25, 813]]\n",
      "training time:  0.25000810000346974\n",
      "validation time:  1.7196112999808975\n",
      "200 features:\n",
      "93.55828220858896\n",
      "[[103, 37], [26, 812]]\n",
      "training time:  0.35506130001158454\n",
      "validation time:  2.5181722000124864\n",
      "300 features:\n",
      "93.96728016359918\n",
      "[[108, 32], [27, 811]]\n",
      "training time:  0.7607785000000149\n",
      "validation time:  2.91989449999528\n",
      "400 features:\n",
      "94.98977505112475\n",
      "[[115, 25], [24, 814]]\n",
      "training time:  1.1247887999925297\n",
      "validation time:  4.190703800006304\n",
      "500 features:\n",
      "94.98977505112475\n",
      "[[116, 24], [25, 813]]\n",
      "training time:  0.715164499997627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/252096302.py:77: RuntimeWarning: divide by zero encountered in log\n",
      "  prediction_label_0 += np.log(probabilityOfNonSpam)\n",
      "C:\\Users\\sezin\\AppData\\Local\\Temp/ipykernel_20444/252096302.py:78: RuntimeWarning: divide by zero encountered in log\n",
      "  prediction_label_1 += np.log(probabilityOfSpam)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation time:  3.8271329999843147\n",
      "600 features:\n",
      "94.88752556237219\n",
      "[[113, 27], [23, 815]]\n"
     ]
    }
   ],
   "source": [
    "print('t1')\n",
    "training_1_f = eliminate_except(train_features,select100)\n",
    "print('t2')\n",
    "training_2_f = eliminate_except(train_features,select200)\n",
    "print('t3')\n",
    "training_3_f = eliminate_except(train_features,select300)\n",
    "print('t4')\n",
    "training_4_f = eliminate_except(train_features,select400)\n",
    "print('t5')\n",
    "training_5_f = eliminate_except(train_features,select500)\n",
    "print('t6')\n",
    "training_6_f = eliminate_except(train_features,select600)\n",
    "test_1_f = eliminate_except(test_features,select100)\n",
    "test_2_f = eliminate_except(test_features,select200)\n",
    "test_3_f = eliminate_except(test_features,select300)\n",
    "test_4_f = eliminate_except(test_features,select400)\n",
    "test_5_f = eliminate_except(test_features,select500)\n",
    "test_6_f = eliminate_except(test_features,select600)\n",
    "\n",
    "naiveBayes21 = bernoulliNaiveBayes(training_1_f,train_labels)\n",
    "predictions = []\n",
    "start = timeit.default_timer()\n",
    "for j in range(0,len(test_labels)):\n",
    "    prediction = naiveBayes21.predict(test_1_f[j])\n",
    "    predictions.append(prediction)\n",
    "stop = timeit.default_timer()\n",
    "print('validation time: ', stop - start)\n",
    "print('100 features:')\n",
    "print(calc_accuracy(test_labels , predictions))\n",
    "print(confusion_matrix(test_labels , predictions))\n",
    "\n",
    "naiveBayes22 = bernoulliNaiveBayes(training_2_f,train_labels)\n",
    "predictions = []\n",
    "start = timeit.default_timer()\n",
    "for j in range(0,len(test_labels)):\n",
    "    prediction = naiveBayes22.predict(test_2_f[j])\n",
    "    predictions.append(prediction)\n",
    "stop = timeit.default_timer()\n",
    "print('validation time: ', stop - start)\n",
    "print('200 features:')\n",
    "print(calc_accuracy(test_labels , predictions))\n",
    "print(confusion_matrix(test_labels , predictions))\n",
    "\n",
    "naiveBayes23 = bernoulliNaiveBayes(training_3_f,train_labels)\n",
    "predictions = []\n",
    "start = timeit.default_timer()\n",
    "for j in range(0,len(test_labels)):\n",
    "    prediction = naiveBayes23.predict(test_3_f[j])\n",
    "    predictions.append(prediction)\n",
    "stop = timeit.default_timer()\n",
    "print('validation time: ', stop - start)\n",
    "print('300 features:')\n",
    "print(calc_accuracy(test_labels , predictions))\n",
    "print(confusion_matrix(test_labels , predictions))\n",
    "\n",
    "naiveBayes24 = bernoulliNaiveBayes(training_4_f,train_labels)\n",
    "predictions = []\n",
    "start = timeit.default_timer()\n",
    "for j in range(0,len(test_labels)):\n",
    "    prediction = naiveBayes24.predict(test_4_f[j])\n",
    "    predictions.append(prediction)\n",
    "stop = timeit.default_timer()\n",
    "print('validation time: ', stop - start)\n",
    "print('400 features:')\n",
    "print(calc_accuracy(test_labels , predictions))\n",
    "print(confusion_matrix(test_labels , predictions))\n",
    "\n",
    "naiveBayes25 = bernoulliNaiveBayes(training_5_f,train_labels)\n",
    "predictions = []\n",
    "start = timeit.default_timer()\n",
    "for j in range(0,len(test_labels)):\n",
    "    prediction = naiveBayes25.predict(test_5_f[j])\n",
    "    predictions.append(prediction)\n",
    "stop = timeit.default_timer()\n",
    "print('validation time: ', stop - start)\n",
    "print('500 features:')\n",
    "print(calc_accuracy(test_labels , predictions))\n",
    "print(confusion_matrix(test_labels , predictions))\n",
    "\n",
    "naiveBayes26 = bernoulliNaiveBayes(training_6_f,train_labels)\n",
    "predictions = []\n",
    "start = timeit.default_timer()\n",
    "for j in range(0,len(test_labels)):\n",
    "    prediction = naiveBayes26.predict(test_6_f[j])\n",
    "    predictions.append(prediction)\n",
    "stop = timeit.default_timer()\n",
    "print('validation time: ', stop - start)\n",
    "print('600 features:')    \n",
    "print(calc_accuracy(test_labels , predictions))\n",
    "print(confusion_matrix(test_labels , predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11be7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
